{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimGNN-Implementation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZvDqcbO9RlP",
        "outputId": "37224edb-3781-423a-b30a-f49f984c8e89"
      },
      "source": [
        "import torch\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device, torch.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0 1.9.0+cu102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48iLmgjV9hG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b583a7f-00f4-475d-a772-477d4c09b0c4"
      },
      "source": [
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch-geometric\n",
        "import torch_geometric"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.7)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.10)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (1.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.5.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (5.0.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (0.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbDAQ1Vz91ZM"
      },
      "source": [
        "# **1) Attention Layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq7ZWsSc99EF"
      },
      "source": [
        "from torch_scatter import scatter_mean, scatter_add\n",
        "\n",
        "# Defining the Attention Mechanism as a Separate Class of itself\n",
        "class AttentionLayer(torch.nn.Module):\n",
        "    def __init__(self, d = 16, activation=2, a = 0.1):\n",
        "        \"\"\"\n",
        "        :param: d: Output Dimension of the Node Embeddings\n",
        "        :param: activation: The Activation Function to be used for the Attention Layer\n",
        "        :param: a: Slope of the -ve part if the activation is Leaky ReLU\n",
        "        \"\"\"\n",
        "        super(AttentionLayer, self).__init__()\n",
        "        self.d = d # Output dimension of the Convolution Vector for each Node\n",
        "        self.activation = activation \n",
        "        self.a = a # Slope of the negative part in Leaky-ReLU\n",
        "        \n",
        "        self.params()\n",
        "        self.initialize()\n",
        "        \n",
        "    def params(self):\n",
        "        self.W_att = torch.nn.Parameter(torch.Tensor(self.d, self.d))\n",
        "\n",
        "    def initialize(self):\n",
        "        \"\"\"\n",
        "        Initialization depends upon the activation function used.\n",
        "        If ReLU/ Leaky ReLU : He (Kaiming) Initialization\n",
        "        If tanh/ sigmoid : Xavier Initialization\n",
        "        0-ReLU, 1-Leaky ReLU, 2-tanh, 3-sigmoid\n",
        "        \"\"\"\n",
        "        non_lin = {0:\"relu\", 1:\"leaky_relu\", 2:\"tanh\", 3:\"sigmoid\"}\n",
        "        \n",
        "        if (self.activation==1) or (self.activation==0):\n",
        "            torch.nn.init.kaiming_normal_(self.W_att, a=self.a, nonlinearity=non_lin[self.activation])\n",
        "        elif (self.activation==2) or (self.activation==3):\n",
        "            torch.nn.init.xavier_normal_(self.W_att)\n",
        "        else:\n",
        "            raise ValueError(\"Activation can only take values 0,1,2,3!\")\n",
        "\n",
        "    def forward(self, node_embeddings, batch, size = None):\n",
        "        \"\"\" \n",
        "        :param: node_embeddings :(N_B x D) Tensor containing Node Embeddings\n",
        "        :param: batch : Tensor containing the Graph to which Each Node in the Batch belongs\n",
        "        :param: size : Check Documentation https://pytorch-scatter.readthedocs.io/en/1.3.0/functions/mean.html\n",
        "        :return: global_graph_embedding for each graph in the batch\n",
        "        \"\"\"\n",
        "        size = batch[-1].item()+1 if size is None else size # Gives Batch Size = B\n",
        "        \n",
        "        global_context = scatter_mean(node_embeddings,index = batch, dim=0, dim_size = size) # (N_B,D) -> (B,D) (mean)\n",
        "        global_context = torch.matmul(global_context, self.W_att) # (B,D) x (D,D) -> (B,D)\n",
        "        \n",
        "        # Applying the Non-Linearity over W_att*mean(U_i), the default is tanh\n",
        "        if self.activation==2:\n",
        "            global_context = torch.tanh(global_context)\n",
        "        elif self.activation==1:\n",
        "            leaky_relu = torch.nn.LeakyReLU()\n",
        "            global_context = leaky_relu(global_context)\n",
        "        elif self.activation==0:\n",
        "            global_context = global_context.relu()\n",
        "        elif self.activation==3:\n",
        "            global_context = torch.sigmoid(global_context)\n",
        "        \n",
        "        # Getting the attention value for each Node for a Given Graph\n",
        "        e = torch.sum(node_embeddings*global_context[batch], dim=1) # (N_B,D) * (N_B,D) -> (N_B,1) (due to sum along dimension D) \n",
        "        attn_weights = e.sigmoid() # (N_B, 1)\n",
        "        \n",
        "        # Calculating the Global Graph Embedding\n",
        "        global_graph_embedding = scatter_add(node_embeddings*attn_weights.unsqueeze(-1),\n",
        "                                             index=batch, dim=0, dim_size=size) # (N_B,D) x (N_B,1) -> (B,D)\n",
        "        \n",
        "        return global_graph_embedding"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAGbUYcmAg5l"
      },
      "source": [
        "# **2) Neural Tensor Network Layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l-BA5-0AlFV"
      },
      "source": [
        "# Defining the Neural Tensor Network Layer as a Separate Class of Itself\n",
        "class NTNLayer(torch.nn.Module):\n",
        "    def __init__(self, d=16, k=16, activation=0, a = 0.1):\n",
        "        \"\"\"\n",
        "        :param: d: Input Dimension of the NTN - i.e Dimension of the Graph/ Node Embeddings\n",
        "        :param: k: Output Dimension of the NTN - No. of Similarity Scores to output\n",
        "        :param: activation: Activation Function to be used for the NTN - Default = ReLU\n",
        "        :param: a: Slope of the negative part for a Leaky ReLU activation\n",
        "        \"\"\"\n",
        "        super(NTNLayer, self).__init__()\n",
        "        self.d = d # Input Dimension of the NTN\n",
        "        self.k = k # Output dimension of the NTN\n",
        "        self.a = a # Slope in case of Leaky ReLU initialization \n",
        "        self.activation = activation\n",
        "        self.params()\n",
        "        self.initialize()\n",
        "    \n",
        "    def params(self):\n",
        "        self.W = torch.nn.Parameter(torch.Tensor(self.d,self.d,self.k))\n",
        "        self.V = torch.nn.Parameter(torch.Tensor(self.k, 2*self.d))\n",
        "        self.b = torch.nn.Parameter(torch.Tensor(self.k,1))\n",
        "\n",
        "    def initialize(self): \n",
        "        \"\"\"\n",
        "        Initialization depends upon the activation function used.\n",
        "        If ReLU/ Leaky ReLU : He Initialization\n",
        "        If tanh/ sigmoid : Xavier Initialization\n",
        "        0-ReLU, 1-Leaky ReLU, 2-tanh, 3-sigmoid\n",
        "        \"\"\"\n",
        "        non_lin = {0:\"relu\", 1:\"leaky_relu\", 2:\"tanh\", 3:\"sigmoid\"}\n",
        "        if (self.activation==1) or (self.activation==0):\n",
        "            torch.nn.init.kaiming_normal_(self.W, a=self.a, nonlinearity=non_lin[self.activation])\n",
        "            torch.nn.init.kaiming_normal_(self.V, a=self.a, nonlinearity=non_lin[self.activation])\n",
        "            torch.nn.init.kaiming_normal_(self.b, a=self.a, nonlinearity=non_lin[self.activation])\n",
        "            \n",
        "        elif (self.activation==2) or (self.activation==3):\n",
        "            torch.nn.init.xavier_normal_(self.W)\n",
        "            torch.nn.init.xavier_normal_(self.V)\n",
        "            torch.nn.init.xavier_normal_(self.b)\n",
        "        \n",
        "        else:\n",
        "            raise ValueError(\"Activation can only take values 0,1,2,3!\")\n",
        "        \n",
        "    def forward(self, h1, h2):\n",
        "        \"\"\"Returns 'K' Rough Similarity Scores between the Pair of Graphs\n",
        "        The Neural Tensor Network (NTN) outputs 'K' similarity scores where 'K' is a hyperparameter\n",
        "        :param: h1 : Graph Embedding of Graph 1 - (B,D)\n",
        "        :param: h2 : Graph Embedding of Graph 2 - (B,D)\n",
        "        \"\"\"\n",
        "        B,_ = h1.shape\n",
        "        scores = torch.mm(h1, self.W.view(self.d, -1)) # (B,D) x (D, K+D) -> (B, K+D)\n",
        "        scores = scores.view(B,self.d,self.k) # (B,K+D) -> (B,D,K)\n",
        "        scores = (scores*h2.unsqueeze(-1)).sum(dim=1) # (B,D,K) * (B,D,1) -> (B,K)\n",
        "        \n",
        "        concatenated_rep = torch.cat((h1, h2), dim=1) # (B,2D)\n",
        "        scores = scores + torch.mm(concatenated_rep, self.V.t()) # (B,2D) x (2D,K) -> (B,K)\n",
        "        scores = scores + self.b.t() # (B,K) + (1,K) = (B,K)\n",
        "        \n",
        "        if self.activation==0:\n",
        "            scores = scores.relu()\n",
        "            return scores\n",
        "        elif self.activation==1:\n",
        "            leaky_relu = torch.nn.LeakyReLU()\n",
        "            scores = leaky_relu(scores)\n",
        "            return scores\n",
        "        elif self.activation==2:\n",
        "            scores = torch.tanh(scores)\n",
        "            return scores\n",
        "        elif self.activation==3:\n",
        "            scores = torch.sigmoid(scores)\n",
        "            return scores\n",
        "        else:\n",
        "            raise ValueError(\"Activation can only take values 0,1,2,3!\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX8o_JZ7Cjkt"
      },
      "source": [
        "# **3) SimGNN - Putting it Together**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8Zj-MX2CoK5"
      },
      "source": [
        "# Writing the Entire SimGNN Model\n",
        "from torch_geometric.utils import to_dense_batch, to_dense_adj\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch.nn import Linear\n",
        "\n",
        "class SimGNN(torch.nn.Module):\n",
        "    def __init__(self, num_node_features, hist=True, ntn_layer=True, d=16, k=16, bins = 16):\n",
        "        super(SimGNN, self).__init__()\n",
        "        self.setupHyperParams(hist, ntn_layer, d, k, bins, num_node_features)\n",
        "        self.setupLayers()\n",
        "        \n",
        "    def setupHyperParams(self, hist, ntn_layer, d, k, bins, num_node_features):\n",
        "        self.num_node_features = num_node_features\n",
        "        # Dimension of the Node/ Graph Embeddding\n",
        "        self.d = d\n",
        "        # Output Dimension of the NTN\n",
        "        self.k = k\n",
        "        # Do we want to include the NTN Layer in the pipeline\n",
        "        self.ntn_layer = ntn_layer\n",
        "        # Do we want to use the histogram strategy\n",
        "        self.hist = hist\n",
        "        # No. of Bins to be used for the Histogram \n",
        "        self.bins = bins\n",
        "    \n",
        "    def fcnnInputDim(self):\n",
        "        \"\"\"Calculate The Input Dimension of the FCNN Layer\"\"\"\n",
        "        if self.hist and self.ntn_layer:\n",
        "            return self.bins+self.k\n",
        "        elif self.hist:\n",
        "            return self.bins + 1\n",
        "        elif self.ntn_layer:\n",
        "            return self.k\n",
        "        else : \n",
        "            # Instead of NTN ,we would just be using a simple dot product\n",
        "            # between the Graph Embeddings to Compute Similarities\n",
        "            return 1\n",
        "    \n",
        "    def setupLayers(self):\n",
        "        fcnn_input_dim = self.fcnnInputDim()\n",
        "        \n",
        "        # Layers of SimGNN\n",
        "        # GCN Layers\n",
        "        self.conv1 = GCNConv(self.num_node_features,64)\n",
        "        self.conv2 = GCNConv(64,32)\n",
        "        self.conv3 = GCNConv(32,self.d)\n",
        "        \n",
        "        # Attention Layer and Neural Tensor Network Layer \n",
        "        self.attention_layer = AttentionLayer(self.d)\n",
        "        self.NTN = NTNLayer(self.d, self.k)\n",
        "        \n",
        "        # Fully Connected Layer\n",
        "        self.linear_1 = torch.nn.Linear(fcnn_input_dim,16)\n",
        "        self.linear_2 = torch.nn.Linear(16,8)\n",
        "        self.linear_3 = torch.nn.Linear(8,4)\n",
        "        self.linear_4 = torch.nn.Linear(4,1)\n",
        "    \n",
        "    def GCN(self, x, edge_index):\n",
        "        \"\"\"\n",
        "        Implementing the Graph Convolutional Network\n",
        "        :param x : One Hot Encoded Feature Representation of the Nodes\n",
        "        :param edge_index : Tensor Representation of Edges to calculate Adjacency Matrix\n",
        "        :U : (N_B x D) matrix of Node Embeddings\n",
        "        :N_B : Total No. of Nodes in the Batch (irrespective of parent graph) \n",
        "        :D : dimensions of the Node Embeddings (decided by us)\n",
        "        I haven't implemented Dropout/ BatchNorm but can also try to do that\n",
        "        \"\"\"\n",
        "        U = self.conv1(x, edge_index)\n",
        "        U = U.relu()\n",
        "        U = self.conv2(U, edge_index)\n",
        "        U = U.relu()\n",
        "        U = self.conv3(U, edge_index)\n",
        "        return U\n",
        "\n",
        "    def kernel(self, graph_embedding_1, graph_embedding_2):\n",
        "        pass\n",
        "\n",
        "    def rbf_kernel_sim(self, graph_embedding_1, graph_embedding_2):\n",
        "        \"\"\"\n",
        "        :param: graph_embedding_1 : (B,D) dimensional graph embedding\n",
        "        :param: graph_embedding_2 : (B,D) dimensional graph embedding\n",
        "        :return: rbf_sim : RBF Kernel Similarity the two graph embeddings\n",
        "        \"\"\"\n",
        "        distance = graph_embedding_1-graph_embedding_2\n",
        "        distance = torch.sum(distance*distance, dim = 1)\n",
        "        return torch.exp(-distance).view(-1,1)\n",
        "    \n",
        "    def histogram(self, U1, U2, batch1, batch2):\n",
        "        \"\"\" B = Batch Size\n",
        "        To calculate the Histogram Representation of the Pairwise Interaction Tensor\n",
        "        :param: U1 : (N_B1 x D) matrix which encodes the node embeddings of Graph 1\n",
        "        :param: U2 : (N_B2 x D) matrix which encodes the node embeddings of Graph 2\n",
        "        :param: batch1 : Logs the Parent graph of the Nodes\n",
        "        :param: batch2 : Logs the Parent Graph of the Nodes\n",
        "        :return: norm_hist_scores : (B x self.bins) Normalized histogram for each batch\n",
        "        \"\"\"\n",
        "        # Convert U1 and U2 into Dense Matrices\n",
        "        U1, mask1 = to_dense_batch(U1, batch1) # (B, N_max1, D); (B, N_max1)\n",
        "        U2, mask2 = to_dense_batch(U2, batch2) # (B, N_max2, D); (B, N_max2)\n",
        "        B, N_max1, _ = U1.size()\n",
        "        B, N_max2, _ = U2.size()\n",
        "        \n",
        "        # Max Number of Nodes for Each Graph Pair in the Batch\n",
        "        max_total_nodes = torch.max(mask1.sum(dim=1), mask2.sum(dim=1)).view(-1) # (B,1)\n",
        "         \n",
        "        # Calculating Interaction Scores for the entire batch\n",
        "        interaction_scores = torch.matmul(U1, U2.permute(0,2,1)).detach() # (B, N_max1, N_max2)\n",
        "        interaction_scores = torch.sigmoid(interaction_scores)\n",
        "\n",
        "        # Getting the Histogram for each Pair in the batch\n",
        "        hist_score_list = []\n",
        "        for i in range(B):\n",
        "            interaction_matrix = interaction_scores[:,:max_total_nodes[i], :max_total_nodes[i]]\n",
        "            hist_score = torch.histc(interaction_matrix, bins = self.bins).view(-1) # (self.bins,)\n",
        "            hist_score = hist_score/hist_score.sum() # Normalizing the Histogram\n",
        "            hist_score_list.append(hist_score)\n",
        "\n",
        "        return torch.stack(hist_score_list).view(B, self.bins) # (B, self.bins)\n",
        "    \n",
        "    def FCNN(self, x):\n",
        "        \"\"\":param: x: Rough Similarity Scores of 'B' Graph Pairs where B is Batch Size\"\"\"\n",
        "        ged_sim = self.linear_1(x)\n",
        "        ged_sim = ged_sim.relu()\n",
        "        \n",
        "        ged_sim = self.linear_2(ged_sim)\n",
        "        ged_sim = ged_sim.relu()\n",
        "        \n",
        "        ged_sim = self.linear_3(ged_sim)\n",
        "        ged_sim = ged_sim.relu()\n",
        "        ged_sim = self.linear_4(ged_sim)\n",
        "        \n",
        "        return ged_sim\n",
        "    \n",
        "    def forward(self, data):\n",
        "        \"\"\"\n",
        "         Forward pass with graphs.\n",
        "         :param data: A Batch Containing a Pair of Graphs.\n",
        "         :return score: Similarity score.\n",
        "         \"\"\"\n",
        "        edge_index_1 = data.edge_index_1\n",
        "        edge_index_2 = data.edge_index_2\n",
        "        x1, x2 = data.x1, data.x2\n",
        "        x1_batch , x2_batch = data.x1_batch, data.x2_batch\n",
        "\n",
        "        # Passed through GCN\n",
        "        node_embeddings_1 = self.GCN(x1, edge_index_1)\n",
        "        node_embeddings_2 = self.GCN(x2, edge_index_2)\n",
        "\n",
        "        # Passed through Attention Layer to get Graph Embedding\n",
        "        graph_embedding_1 = self.attention_layer(node_embeddings_1, x1_batch)\n",
        "        graph_embedding_2 = self.attention_layer(node_embeddings_2, x2_batch)\n",
        "        \n",
        "        # Passed through Neural Tensor Network if allowed otherwise just take a simple Inner Product\n",
        "        if self.ntn_layer:\n",
        "            scores = self.NTN(graph_embedding_1, graph_embedding_2)\n",
        "        else:\n",
        "            scores = self.rbf_kernel_sim(graph_embedding_1, graph_embedding_2)\n",
        "            \n",
        "        # Computed Histogram from the Node Embeddings (Strategy 2)\n",
        "        if self.hist:\n",
        "            hist = self.histogram(node_embeddings_1, node_embeddings_2, x1_batch, x2_batch)\n",
        "            scores = torch.cat((scores, hist), dim=1) # (B, K+self.bins)\n",
        "\n",
        "        # Pass through the Fully Connected Neural Network Layer to get Graph Edit Distance Similarity\n",
        "        ged_pred = self.FCNN(scores)\n",
        "        \n",
        "        return ged_pred.view(-1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOSZQfalF-Go"
      },
      "source": [
        "# **4) Loading Data & Feature Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD4z2XVPGCTI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2f30162-f215-4885-b264-a70583e0b596"
      },
      "source": [
        "name = \"LINUX\"\n",
        "from torch_geometric.datasets import GEDDataset\n",
        "train_graphs = GEDDataset(root=\"./data/train\", train = True, name=name)\n",
        "test_graphs = GEDDataset(root=\"./data/test\", train = False, name=name)\n",
        "\n",
        "print(f\"Number of Graphs in Train Set : {len(train_graphs)}\")\n",
        "print(f\"Number of Graphs in Test Set : {len(test_graphs)}\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Graphs in Train Set : 800\n",
            "Number of Graphs in Test Set : 200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5qV6Z7KI1aA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d48ff60b-6856-40fb-bada-9f6d816619e5"
      },
      "source": [
        "i = 1\n",
        "print(train_graphs[i])\n",
        "print(test_graphs[i])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data(edge_index=[2, 8], i=[1])\n",
            "Data(edge_index=[2, 14], i=[1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfBXgAbqHK2k"
      },
      "source": [
        "## **a) Creating a Feature Matrix for the Graphs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06jh6UrsGHy0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb5b7dd1-387b-4ad6-b41e-34b48a4b7c53"
      },
      "source": [
        "from torch_geometric.transforms import OneHotDegree\n",
        "from torch_geometric.utils import degree\n",
        "\n",
        "# If the dataset does not have a feature matrix, we create one!\n",
        "# Only the AIDS700nef Dataset has an inbuilt feature matrix\n",
        "# We create a One Hot Encoded Degree Feature Matrix\n",
        "if train_graphs[0].x is None:\n",
        "            max_degree = 0\n",
        "            for graph in train_graphs + test_graphs:\n",
        "                # If this graph has edges then do\n",
        "                if graph.edge_index.size(1) > 0:\n",
        "                    max_degree = max(max_degree, int(degree(graph.edge_index[0]).max().item()))\n",
        "            \n",
        "            # Create the feature matrix for the Dataset\n",
        "            one_hot_degree = OneHotDegree(max_degree, cat=False)\n",
        "            train_graphs.transform = one_hot_degree\n",
        "            test_graphs.transform = one_hot_degree\n",
        "\n",
        "num_node_features = train_graphs.num_features\n",
        "num_edge_features = train_graphs.num_edge_features\n",
        "print(num_node_features, num_edge_features)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvcxuzuiHECX"
      },
      "source": [
        "## **b) Making Pairs of Graphs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XKhDc76GqdA"
      },
      "source": [
        "class makeGraphPairs(torch_geometric.data.Data):\n",
        "    \"\"\" Documentation\n",
        "    :param: edge_index_1 : Edge Index of the First Graph\n",
        "    :param: edge_index_2 : Edge Index of the Second Graph in the pair\n",
        "    :param: x_1 : Feature Matrix of the First Graph in the Pair\n",
        "    :param: x_2 : Feature Matrix of the Second Graph in the Pair\n",
        "       \n",
        "    :returns: torch_geometric.data.Data object which comprises two graphs\n",
        "    \"\"\"\n",
        "    def __init__(self, edge_index_1, x1, edge_index_2, x2, ged, norm_ged, graph_sim):\n",
        "        super(makeGraphPairs, self).__init__()\n",
        "        self.edge_index_1 = edge_index_1\n",
        "        self.x1 = x1\n",
        "        self.edge_index_2 = edge_index_2\n",
        "        self.x2 = x2\n",
        "        self.ged = ged\n",
        "        self.norm_ged = norm_ged\n",
        "        self.graph_sim = graph_sim\n",
        "\n",
        "    def __inc__(self, key, value):\n",
        "        if key == \"edge_index_1\":\n",
        "            return self.x1.size(0)\n",
        "        elif key == \"edge_index_2\":\n",
        "            return self.x2.size(0)\n",
        "        else:\n",
        "            return super().__inc__(key, value)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBTED2zKIC-7"
      },
      "source": [
        "### **i. For Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZW5jrubHaff"
      },
      "source": [
        "\"\"\"TRAINING SET PAIR\"\"\"\n",
        "# Data List to pass into the Data Loader to get Batches\n",
        "train_graph_pair_list = []\n",
        "\n",
        "# Making the Pairs of Graphs\n",
        "for graph1_num, graph1 in enumerate(train_graphs):\n",
        "    # To avoid double counting\n",
        "    for graph2 in train_graphs[graph1_num:]:\n",
        "        # Initializing Data\n",
        "        edge_index_1 = graph1.edge_index\n",
        "        x1 = graph1.x\n",
        "        edge_index_2 = graph2.edge_index\n",
        "        x2 = graph2.x\n",
        "        ged = train_graphs.ged[graph1.i, graph2.i]\n",
        "        norm_ged = train_graphs.norm_ged[graph1.i, graph2.i]\n",
        "        graph_sim = torch.exp(-norm_ged)\n",
        "        \n",
        "        # Making Graph Pair\n",
        "        graph_pair = makeGraphPairs(edge_index_1=edge_index_1, x1=x1, \n",
        "                                    edge_index_2=edge_index_2, x2=x2,\n",
        "                                    ged=ged ,norm_ged=norm_ged, graph_sim = graph_sim)\n",
        "        \n",
        "        # Saving all the Graph Pairs to the List for Batching and Data Loading\n",
        "        train_graph_pair_list.append(graph_pair)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOJWjpv6IHZ2"
      },
      "source": [
        "### **ii. For Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ak5ROuiHlgd"
      },
      "source": [
        "\"\"\"TEST SET PAIR\"\"\"\n",
        "# Data List to pass into the Data Loader to get batches\n",
        "test_graph_pair_list = []\n",
        "\n",
        "# Making the Pairs of Graphs\n",
        "for graph1 in test_graphs:\n",
        "    for graph2 in train_graphs:\n",
        "        # Initializing Data\n",
        "        edge_index_1 = graph1.edge_index\n",
        "        x1 = graph1.x\n",
        "        edge_index_2 = graph2.edge_index\n",
        "        x2 = graph2.x\n",
        "        ged = train_graphs.ged[graph1.i, graph2.i]\n",
        "        norm_ged = train_graphs.norm_ged[graph1.i, graph2.i]\n",
        "        graph_sim = torch.exp(-norm_ged)\n",
        "        \n",
        "        # Making Graph Pair\n",
        "        graph_pair = makeGraphPairs(edge_index_1=edge_index_1, x1=x1, \n",
        "                                    edge_index_2=edge_index_2, x2=x2,\n",
        "                                    ged=ged ,norm_ged=norm_ged, graph_sim = graph_sim)\n",
        "        \n",
        "        # Saving all the Graph Pairs to the List for Batching and Data Loading\n",
        "        test_graph_pair_list.append(graph_pair)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFslQnWbIOhb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eafc1bc-a11c-4eee-fc3b-f78fc2bad6b7"
      },
      "source": [
        "print(\"Number of Training Graph Pairs = {}\".format(len(train_graph_pair_list)))\n",
        "print(\"Number of Training Test Pairs = {}\".format(len(test_graph_pair_list)))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Training Graph Pairs = 157080\n",
            "Number of Training Test Pairs = 78400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEQFPgVHJdeh",
        "outputId": "4a519df8-c83f-437d-b730-8dea377a9872"
      },
      "source": [
        "test_graph_pair_list[1]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "makeGraphPairs(edge_index_1=[2, 20], edge_index_2=[2, 16], ged=[1], graph_sim=[1], norm_ged=[1], x1=[10, 29], x2=[9, 29])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waUgvHJIIeLe"
      },
      "source": [
        "# **5) Training Begins**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnCYdo1VJ2uy"
      },
      "source": [
        "batch_size = 128\n",
        "from torch_geometric.data import DataLoader\n",
        "train_loader = DataLoader(train_graph_pair_list, batch_size = batch_size, follow_batch = [\"x1\", \"x2\"], shuffle = True)\n",
        "test_loader = DataLoader(test_graph_pair_list, batch_size = batch_size, follow_batch = [\"x1\", \"x2\"], shuffle = True)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QUJqmRwKPiH",
        "outputId": "1cdd6dbc-332d-4516-e625-bb65b47536af"
      },
      "source": [
        "batch = next(iter(train_loader))\n",
        "#batch = batch.to(device)\n",
        "print(batch)\n",
        "print(batch.edge_index_1.get_device())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch(edge_index_1=[2, 1708], edge_index_2=[2, 1756], ged=[128], graph_sim=[128], norm_ged=[128], x1=[946, 8], x1_batch=[946], x2=[956, 8], x2_batch=[956])\n",
            "-1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GOw1NSANtGf",
        "outputId": "7bea5a7d-836e-49ed-8b7c-3f5d2bbf335f"
      },
      "source": [
        "num_iters = len(train_loader)\n",
        "print(num_iters)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2504\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsxsA1PtR85B"
      },
      "source": [
        "def evaluate(dataloader, model):\n",
        "    loss = 0\n",
        "    num_ex = 0\n",
        "    model.eval()\n",
        "    for data in dataloader:\n",
        "        data = data.to(device)\n",
        "        y_pred = model(data)\n",
        "        l = loss_criterion(y_pred, data.graph_sim)\n",
        "        loss = (loss*num_ex + l*len(data.ged))/(num_ex+len(data.ged))\n",
        "        num_ex += len(data.ged)\n",
        "    model.train()\n",
        "    return loss.item()\n",
        "\n",
        "def evaluate_test(dataloader, model):\n",
        "    test_loss = []\n",
        "    model.eval()\n",
        "    for data in dataloader:\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        data = data.to(device)\n",
        "        y_pred = model(data)\n",
        "        test_loss.append(loss_criterion(y_pred, data.graph_sim))\n",
        "    model.train()\n",
        "    return torch.mean(torch.stack(test_loss)).item()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6Tza6rxIn3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f46baadd-14f0-4f4e-dfa4-b98070c084ca"
      },
      "source": [
        "model = SimGNN(num_node_features, ntn_layer = False).to(device)\n",
        "loss_criterion = torch.nn.MSELoss()\n",
        "opt = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "epochs = 10000//num_iter+1\n",
        "min_loss = 1000\n",
        "\n",
        "import time\n",
        "import copy\n",
        "train_loss_arr = []\n",
        "test_loss_arr = []\n",
        "tik = time.time()\n",
        "\n",
        "for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
        "    for i, data in enumerate(train_loader):\n",
        "        opt.zero_grad()\n",
        "        data = data.to(device)\n",
        "        y_pred = model(data)\n",
        "        loss = loss_criterion(y_pred.view(-1), data.graph_sim)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        \n",
        "        # Model Checkpointing\n",
        "        if min_loss>loss.item():\n",
        "            min_loss = loss.item()\n",
        "            best_model = copy.deepcopy(model.state_dict())\n",
        "            #print('Min loss %0.2f' % min_loss)\n",
        "        \n",
        "        # Printing Loss Values\n",
        "        if i%200 == 0:\n",
        "            print(f\"Iteration: {i}/{num_iters}, Train Loss: {loss}\")\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        train_loss_arr.append(loss.item())\n",
        "    \n",
        "    # Printing Epoch Summary\n",
        "    print(\"Epoch: {}/{}, Train MSE: {}, Test MSE: {}\".format(epoch+1, epochs, train_loss_arr[-1],\n",
        "                                                          evaluate_test(test_loader, model)))\n",
        "\n",
        "tok = time.time()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Epochs:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 0/2504, Train Loss: 0.7502843141555786\n",
            "Iteration: 200/2504, Train Loss: 0.021033501252532005\n",
            "Iteration: 400/2504, Train Loss: 0.0056993719190359116\n",
            "Iteration: 600/2504, Train Loss: 0.0035994937643408775\n",
            "Iteration: 800/2504, Train Loss: 0.0028360383585095406\n",
            "Iteration: 1000/2504, Train Loss: 0.0028485930524766445\n",
            "Iteration: 1200/2504, Train Loss: 0.002874080091714859\n",
            "Iteration: 1400/2504, Train Loss: 0.002712225541472435\n",
            "Iteration: 1600/2504, Train Loss: 0.002897716360166669\n",
            "Iteration: 1800/2504, Train Loss: 0.0023131719790399075\n",
            "Iteration: 2000/2504, Train Loss: 0.002750932704657316\n",
            "Iteration: 2200/2504, Train Loss: 0.0021342968102544546\n",
            "Iteration: 2400/2504, Train Loss: 0.0028644856065511703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Epochs:  25%|██▌       | 1/4 [02:59<08:59, 179.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/4, Train MSE: 0.0036061073187738657, Test MSE: 0.0024018194526433945\n",
            "Iteration: 0/2504, Train Loss: 0.0030047420877963305\n",
            "Iteration: 200/2504, Train Loss: 0.0024389917962253094\n",
            "Iteration: 400/2504, Train Loss: 0.0019758231937885284\n",
            "Iteration: 600/2504, Train Loss: 0.0023972210474312305\n",
            "Iteration: 800/2504, Train Loss: 0.0023838933557271957\n",
            "Iteration: 1000/2504, Train Loss: 0.0025604479014873505\n",
            "Iteration: 1200/2504, Train Loss: 0.0016578438226133585\n",
            "Iteration: 1400/2504, Train Loss: 0.002563946880400181\n",
            "Iteration: 1600/2504, Train Loss: 0.0016224486753344536\n",
            "Iteration: 1800/2504, Train Loss: 0.001962751615792513\n",
            "Iteration: 2000/2504, Train Loss: 0.0018017145339399576\n",
            "Iteration: 2200/2504, Train Loss: 0.00195359718054533\n",
            "Iteration: 2400/2504, Train Loss: 0.001974451122805476\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Epochs:  50%|█████     | 2/4 [05:59<05:59, 179.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2/4, Train MSE: 0.0029230061918497086, Test MSE: 0.0019535261671990156\n",
            "Iteration: 0/2504, Train Loss: 0.0021883463487029076\n",
            "Iteration: 200/2504, Train Loss: 0.0018010175554081798\n",
            "Iteration: 400/2504, Train Loss: 0.0017277435399591923\n",
            "Iteration: 600/2504, Train Loss: 0.0015086641069501638\n",
            "Iteration: 800/2504, Train Loss: 0.002586269285529852\n",
            "Iteration: 1000/2504, Train Loss: 0.0026873848401010036\n",
            "Iteration: 1200/2504, Train Loss: 0.0018747685244306922\n",
            "Iteration: 1400/2504, Train Loss: 0.0014993059448897839\n",
            "Iteration: 1600/2504, Train Loss: 0.001346586854197085\n",
            "Iteration: 1800/2504, Train Loss: 0.0013177655637264252\n",
            "Iteration: 2000/2504, Train Loss: 0.0013839115854352713\n",
            "Iteration: 2200/2504, Train Loss: 0.0016591805033385754\n",
            "Iteration: 2400/2504, Train Loss: 0.0017407929990440607\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Epochs:  75%|███████▌  | 3/4 [08:57<02:59, 179.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 3/4, Train MSE: 0.001089904340915382, Test MSE: 0.001594069297425449\n",
            "Iteration: 0/2504, Train Loss: 0.0013874333817511797\n",
            "Iteration: 200/2504, Train Loss: 0.001351002138108015\n",
            "Iteration: 400/2504, Train Loss: 0.0015436707763001323\n",
            "Iteration: 600/2504, Train Loss: 0.0018152616685256362\n",
            "Iteration: 800/2504, Train Loss: 0.0016619896050542593\n",
            "Iteration: 1000/2504, Train Loss: 0.001385468989610672\n",
            "Iteration: 1200/2504, Train Loss: 0.0012871171347796917\n",
            "Iteration: 1400/2504, Train Loss: 0.0014706326182931662\n",
            "Iteration: 1600/2504, Train Loss: 0.0020777322351932526\n",
            "Iteration: 1800/2504, Train Loss: 0.0014106656890362501\n",
            "Iteration: 2000/2504, Train Loss: 0.001365435542538762\n",
            "Iteration: 2200/2504, Train Loss: 0.001399458386003971\n",
            "Iteration: 2400/2504, Train Loss: 0.0014049190795049071\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Epochs: 100%|██████████| 4/4 [11:52<00:00, 178.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4/4, Train MSE: 0.0015241203363984823, Test MSE: 0.0014165552565827966\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "K7CBMMWbc1fu",
        "outputId": "9be8855a-dcd5-4f48-9569-9bd3c8a195f6"
      },
      "source": [
        "print(\"========================================================\")\n",
        "print(f\"Time taken for Training = {(tok-tik)}s\")\n",
        "plt.plot(train_loss_arr[:], label = \"Train Loss\")\n",
        "plt.plot(test_loss_arr, label = \"Test Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Loss Curves\")\n",
        "plt.xlabel(\"No. of Iterations\")\n",
        "plt.ylabel(\"MSE Loss\")\n",
        "plt.show()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "========================================================\n",
            "Time taken for Training = 712.7607362270355s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lFItoHui0Jz",
        "outputId": "5914c109-6fa6-4091-cb77-de1a8f64411b"
      },
      "source": [
        "model.load_state_dict(best_model)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcYP8zBoCS1s",
        "outputId": "518b1fd3-9a7a-4b8c-8fd8-b6a80d3fdd74"
      },
      "source": [
        "evaluate_test(test_loader, model)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0014558141119778156"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjTqw0_5DPGT"
      },
      "source": [
        "#torch.save(model,f'simgnn-{name}.pth')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}